{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import mechanism_with_policy_graph\n",
    "import mechanism\n",
    "import map_processor\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def cp_n_split(n_subgraph_x_nodes):\n",
    "    return math.ceil(n_x_lattice/n_subgraph_x_nodes)\n",
    "\n",
    "def perturb(mec, mp, epsilon=1, sample_num=200, sample_states=None, fix=None):\n",
    "    if sample_states is None:\n",
    "        sample_states = mp.possible_states\n",
    "    \n",
    "    set_of_connected_states = mp.make_set_of_connected_states(mp.possible_states, mp.graph_mat)\n",
    "    mec.policy_mat = mp.graph_mat\n",
    "    \n",
    "    if fix is not None:\n",
    "        true_states = [fix] * sample_num\n",
    "    else:\n",
    "        true_states = [np.random.choice(sample_states) for _ in range(sample_num)]\n",
    "    perturbed_states = []\n",
    "    \n",
    "    for true_state in true_states:\n",
    "        true_coord = mp.state_to_coord(true_state)\n",
    "        \n",
    "        connected_states_of_true_state = mp.connected_states(true_state, set_of_connected_states)\n",
    "        connected_coords_of_true_state = mp.states_to_coords(connected_states_of_true_state)\n",
    "        \n",
    "        mec.load(connected_coords_of_true_state, connected_states_of_true_state)\n",
    "        mec.build_distribution(epsilon)\n",
    "        \n",
    "        perturbed_coord = mec.perturb(true_coord)\n",
    "        perturbed_state = mp.find_nearest_state(perturbed_coord)\n",
    "        mapped_perturbed_coord = mp.state_to_coord(perturbed_state)\n",
    "        \n",
    "        perturbed_states.append(perturbed_state)\n",
    "    \n",
    "    return true_states, perturbed_states, mp\n",
    "\n",
    "def perturb_by_epsilons(mec, mp, epsilons, sample_states=None, fix=None, sample_num=200):\n",
    "    results = []\n",
    "    for epsilon in epsilons:\n",
    "        print(\"epsilon:\", epsilon)\n",
    "        results.append(perturb(mec, mp, epsilon, sample_states=sample_states, fix=fix, sample_num=sample_num))\n",
    "    return results\n",
    "    \n",
    "def E_eu(result):\n",
    "    true_states, perturbed_states, mp = result\n",
    "    \n",
    "    true_coords = mp.states_to_coords(true_states)\n",
    "    perturbed_coords = mp.states_to_coords(perturbed_states)\n",
    "    \n",
    "    return np.average(np.linalg.norm(true_coords - perturbed_coords, axis=1) / 1000) * mp.lattice_length\n",
    "\n",
    "def E_r(result, mp):\n",
    "    true_states, perturbed_states, _ = result\n",
    "    \n",
    "    is_same_areas = [mp.is_same_area(true_state, perturbed_state) for true_state, perturbed_state in zip(true_states, perturbed_states)]\n",
    "    \n",
    "    return 1 - np.sum(is_same_areas)/len(is_same_areas)\n",
    "\n",
    "def E_poi(result, mp):\n",
    "    true_states, perturbed_states, _ = result\n",
    "    \n",
    "    assert all([mp.is_in(true_state) for true_state in true_states])\n",
    "    \n",
    "    is_same_cats = [mp.is_in(perturbed_state) for perturbed_state in perturbed_states]\n",
    "    \n",
    "    return 1 - np.sum(is_same_cats)/len(is_same_cats)\n",
    "    \n",
    "def plot_same(epsilons, pim_sames, lm_sames, filename=\"temp\"):\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.plot(epsilons, pim_sames, label=\"P-PIM\")\n",
    "    plt.plot(epsilons, lm_sames, label=\"P-LM\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"$\\epsilon$\")\n",
    "    plt.ylabel(\"same probability\")\n",
    "    plt.savefig(imgdir + filename + \"_same.eps\", bbox_inches='tight', pad_inches=0,  transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "def plot(pim_results, lm_results, filename=\"temp\"):\n",
    "    imgdir = \"\"\n",
    "    \n",
    "    for pim, lm, graph_name in zip(pim_results, lm_results, graph_names):\n",
    "        print(graph_name)\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.plot(epsilons, pim, label=\"P-PIM\", marker=\"o\")\n",
    "        plt.plot(epsilons, lm, label=\"P-LM\", linestyle=\"dotted\", marker=\"x\")\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.xlabel(\"$\\epsilon$\")\n",
    "        plt.ylabel(\"$E_{eu}$\")\n",
    "        plt.savefig(imgdir + filename + graph_name + \".eps\", bbox_inches='tight', pad_inches=0,  transparent=False)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "def plot_bar(results, y_name, filename=\"temp\"):\n",
    "    k9, k16, k25, poi = results\n",
    "    \n",
    "    x = np.arange(len(epsilons))\n",
    "    width = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width*3/2, k9, width, label='K9')\n",
    "    rects2 = ax.bar(x - width/2, k16, width, label='K16')\n",
    "    rects3 = ax.bar(x + width/2, k25, width, label='K25')\n",
    "    rects4 = ax.bar(x + width*3/2, poi, width, label='POI')\n",
    "    ax.set_xticks(x)\n",
    "    \n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend(loc = \"best\", fontsize=8, ncol=2)\n",
    "    ax.set_ylabel('$E_{}$'.format(\"{\" + y_name + \"}\"))\n",
    "    ax.set_xticklabels(epsilons)\n",
    "    plt.xlabel(\"$\\epsilon$\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(filename + \".eps\", bbox_inches='tight', pad_inches=0,  transparent=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x_lattice = 50\n",
    "sample_num = 2000\n",
    "\n",
    "placeID = 3\n",
    "min_lon, max_lon, min_lat, max_lat = 139.6, 139.75, 35.679, 35.8\n",
    "\n",
    "epsilons = [0.3, 0.5, 1, 2]\n",
    "\n",
    "list_n_subgraph_x_nodes = [3,4,5]\n",
    "cat_n_subgraph_x_nodes = 6\n",
    "graph_names = [f\"G_k{num ** 2}\" for num in list_n_subgraph_x_nodes]\n",
    "graph_names.append(f\"G_poi_k{cat_n_subgraph_x_nodes ** 2}\")\n",
    "\n",
    "data_dir = os.path.join(\"/\", \"data\", \"takagi\", \"globefish\")\n",
    "results_dir = os.path.join(data_dir, \"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_processors = []\n",
    "\n",
    "for n_subgraph_x_nodes in list_n_subgraph_x_nodes:\n",
    "    n_split = cp_n_split(n_subgraph_x_nodes)\n",
    "\n",
    "    mp = map_processor.MapProcessor(n_x_lattice)\n",
    "    mp.make_map_from_latlon(min_lon, max_lon, min_lat, max_lat)\n",
    "    mp.make_graph_from_area(n_split=n_split, r=float(\"inf\"))\n",
    "    mp.plot_map()\n",
    "    \n",
    "    map_processors.append(mp)\n",
    "    \n",
    "n_split = cp_n_split(cat_n_subgraph_x_nodes)\n",
    "cat_mp = map_processor.MapProcessor(n_x_lattice)\n",
    "cat_mp.make_map_from_latlon(min_lon, max_lon, min_lat, max_lat)\n",
    "cat_mp.make_graph_from_category_and_area(placeID=placeID, n_split=n_split)\n",
    "cat_mp.plot_map()\n",
    "map_processors.append(cat_mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_with_pg = mechanism_with_policy_graph.PlanarIsotropicMechanismWithPolicyGraph()\n",
    "lm_with_pg = mechanism_with_policy_graph.LaplaceMechanismWithPolicyGraph()\n",
    "\n",
    "pim_results = {graph_name:None for graph_name in graph_names}\n",
    "pim_results_poi = {graph_name:None for graph_name in graph_names}\n",
    "pim_results_part = {graph_name:None for graph_name in graph_names}\n",
    "lm_results = {graph_name:None for graph_name in graph_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mp, graph_name in zip(map_processors, graph_names):\n",
    "    np.random.seed(0)\n",
    "    pim_results[graph_name] = perturb_by_epsilons(pim_with_pg, mp, epsilons, sample_num=sample_num)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    lm_results[graph_name] = perturb_by_epsilons(lm_with_pg, mp, epsilons, sample_num=sample_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_states = map_processors[3].possible_states\n",
    "\n",
    "for mp, graph_name in zip(map_processors, graph_names):\n",
    "    print(graph_name)\n",
    "    np.random.seed(0)\n",
    "    pim_results_poi[graph_name] = perturb_by_epsilons(pim_with_pg, mp, epsilons, sample_states=sample_states, sample_num=sample_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map_processor = map_processors[3]\n",
    "k9_pim_e_poi = [E_poi(pim_results_poi[\"G_k9\"][i], target_map_processor) for i in range(len(epsilons))]\n",
    "k16_pim_e_poi = [E_poi(pim_results_poi[\"G_k16\"][i], target_map_processor) for i in range(len(epsilons))]\n",
    "k25_pim_e_poi = [E_poi(pim_results_poi[\"G_k25\"][i], target_map_processor) for i in range(len(epsilons))]\n",
    "poi_pim_e_poi = [E_poi(pim_results_poi[f\"G_poi_k{36}\"][i], target_map_processor) for i in range(len(epsilons))]\n",
    "plot_bar([k9_pim_e_poi, k16_pim_e_poi, k25_pim_e_poi, poi_pim_e_poi], y_name=\"POI\", filename=f\"poi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k9_pim_e_eus = [E_eu(pim_results[\"G_k9\"][i]) for i in range(len(epsilons))]\n",
    "k16_pim_e_eus = [E_eu(pim_results[\"G_k16\"][i]) for i in range(len(epsilons))]\n",
    "k25_pim_e_eus = [E_eu(pim_results[\"G_k25\"][i]) for i in range(len(epsilons))]\n",
    "poi_pim_e_eus = [E_eu(pim_results[f\"G_poi_k{cat_n_subgraph_x_nodes ** 2}\"][i]) for i in range(len(epsilons))]\n",
    "plot_bar([k9_pim_e_eus, k16_pim_e_eus, k25_pim_e_eus, poi_pim_e_eus], y_name=\"eu\", filename=\"eu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map_processor = map_processors[2]\n",
    "k9_pim_e_rs = [E_r(pim_results[\"G_k9\"][i], target_map_processor) for i in range(len(epsilons))]\n",
    "k16_pim_e_rs = [E_r(pim_results[\"G_k16\"][i], target_map_processor) for i in range(len(epsilons))]\n",
    "k25_pim_e_rs = [E_r(pim_results[\"G_k25\"][i], target_map_processor) for i in range(len(epsilons))]\n",
    "poi_pim_e_rs = [E_r(pim_results[f\"G_poi_k{cat_n_subgraph_x_nodes ** 2}\"][i], target_map_processor) for i in range(len(epsilons))]\n",
    "plot_bar([k9_pim_e_rs, k16_pim_e_rs, k25_pim_e_rs, poi_pim_e_rs], y_name=\"r\", filename=f\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k9_pim_e_eu = [E_eu(pim_results[\"G_k9\"][i]) for i in range(len(epsilons))]\n",
    "k16_pim_e_eu = [E_eu(pim_results[\"G_k16\"][i]) for i in range(len(epsilons))]\n",
    "k25_pim_e_eu = [E_eu(pim_results[\"G_k25\"][i]) for i in range(len(epsilons))]\n",
    "poi_pim_e_eu = [E_eu(pim_results[f\"G_poi_k{cat_n_subgraph_x_nodes ** 2}\"][i]) for i in range(len(epsilons))]\n",
    "\n",
    "k9_lm_e_eu = [E_eu(lm_results[\"G_k9\"][i]) for i in range(len(epsilons))]\n",
    "k16_lm_e_eu = [E_eu(lm_results[\"G_k16\"][i]) for i in range(len(epsilons))]\n",
    "k25_lm_e_eu = [E_eu(lm_results[\"G_k25\"][i]) for i in range(len(epsilons))]\n",
    "poi_lm_e_eu = [E_eu(lm_results[f\"G_poi_k{cat_n_subgraph_x_nodes ** 2}\"][i]) for i in range(len(epsilons))]\n",
    "\n",
    "plot([k9_pim_e_eu, k16_pim_e_eu, k25_pim_e_eu, poi_pim_e_eu], [k9_lm_e_eu, k16_lm_e_eu, k25_lm_e_eu, poi_lm_e_eu])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repair graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x_lattice = 50\n",
    "r = 700\n",
    "epsilon = 1\n",
    "\n",
    "placeID = 3\n",
    "min_lon, max_lon, min_lat, max_lat = 139.6, 139.75, 35.68, 35.8\n",
    "\n",
    "list_n_subgraph_x_nodes = [5, 6, 10, 15, 25]\n",
    "mps = []\n",
    "\n",
    "for n_subgraph_x_nodes in list_n_subgraph_x_nodes:\n",
    "    mp = map_processor.MapProcessor(n_x_lattice)\n",
    "    n_split = mp.cp_n_split(n_subgraph_x_nodes)\n",
    "    mp.make_map_from_latlon(min_lon, max_lon, min_lat, max_lat)\n",
    "    mp.make_area(n_split)\n",
    "    mp.make_graph_from_category_and_distance(placeID=placeID, r=r)\n",
    "    mps.append(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "pim_with_pg = mechanism_with_policy_graph.PlanarIsotropicMechanismWithPolicyGraph()\n",
    "\n",
    "np.random.seed(0)\n",
    "results = []\n",
    "for i, mp in enumerate(mps):\n",
    "    times = []\n",
    "    distances = []\n",
    "    for _ in range(200):\n",
    "        true_state = np.random.choice(mp.possible_states)\n",
    "        area_state = mp.state_to_area_state(true_state)\n",
    "\n",
    "        states = [state for state in mp.areas[area_state] if state in mp.possible_states]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        repaired_graph_mat = map_processor.repair_graph(mp, states)\n",
    "        end_time = time.time()\n",
    "        passed_time = end_time - start_time\n",
    "        print(\"time is:\", passed_time)\n",
    "        coords = mp.states_to_coords(states)\n",
    "        \n",
    "        pim_with_pg.load(coords, states)\n",
    "        pim_with_pg.policy_mat = repaired_graph_mat\n",
    "        \n",
    "        pim_with_pg.build_distribution(epsilon)\n",
    "        \n",
    "        temps = []\n",
    "        for _ in range(200):\n",
    "            sampled = np.random.choice(states)\n",
    "            \n",
    "            true_coord = mp.state_to_coord(sampled)\n",
    "            perturbed_coord = pim_with_pg.perturb(true_coord)\n",
    "            perturbed_state = mp.find_nearest_state(perturbed_coord)\n",
    "            mapped_perturbed_coord = mp.state_to_coord(perturbed_state)\n",
    "\n",
    "            distance = np.linalg.norm(mapped_perturbed_coord - true_coord) * mp.lattice_length\n",
    "            temps.append(distance)\n",
    "\n",
    "        print(\"distance is:\", np.average(temps))\n",
    "        distances.append(np.average(temps))\n",
    "        times.append(passed_time)\n",
    "    results.append((times, distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [(n_subgraph_x_node * mp.lattice_length / 1000) ** 2 for n_subgraph_x_node in list_n_subgraph_x_nodes]\n",
    "\n",
    "distances = [np.average(result[1]) / 1000 for result in results]\n",
    "times = [np.average(result[0]) for result in results]\n",
    "\n",
    "plt.plot(lengths, distances, marker=\"o\")\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.xlabel(\"area of a constraint domain (km$^2$)\")\n",
    "plt.ylabel(\"$E_{eu}$\")\n",
    "plt.savefig(\"repair_graph_domain_eeu.eps\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lengths, times, marker=\"o\")\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.xlabel(\"area of a constraint domain (km$^2$)\")\n",
    "plt.ylabel(\"time (second)\")\n",
    "plt.savefig(\"repair_graph_domain_time.eps\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import trajectory_processor\n",
    "import map_processor\n",
    "import mechanism_with_policy_graph\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def perturb_trajectory(traj, traj_processor, epsilon, mec, iter_num=1, initial_constraint_domain_tp=None):\n",
    "    reports = {\"true_trajectory\": traj[:100], \"perturbed_trajectories\": []}\n",
    "    \n",
    "    mec.policy_mat = traj_processor.graph_mat\n",
    "    \n",
    "    for f in range(iter_num):\n",
    "        \n",
    "        print(\"\\n\" + str(f))\n",
    "        \n",
    "        if initial_constraint_domain_tp:\n",
    "            initial_constraint_domain = initial_constraint_domain_tp.areas[initial_constraint_domain_tp.state_to_area_state(traj[0])]\n",
    "            prob = 1/len(initial_constraint_domain)\n",
    "\n",
    "            prior_distribution = np.zeros(len(traj_processor.transition_mat[0]))\n",
    "            prior_distribution[np.array(initial_constraint_domain)] = prob\n",
    "        else:\n",
    "            prior_distribution = np.zeros(len(traj_processor.transition_mat[0]))\n",
    "            prior_distribution[traj[0]] = 1\n",
    "        \n",
    "        perturbed_trajectory = np.zeros(len(traj[:100]))\n",
    "\n",
    "        for i, true_state in enumerate(traj[:100]):\n",
    "            print(i, end=\"\\r\")\n",
    "\n",
    "            pos_dist = traj_processor.compute_posterior_distribution(prior_distribution)\n",
    "            state_nos = traj_processor.compute_possible_set(pos_dist, delta=0)\n",
    "            \n",
    "            set_of_connected_states = traj_processor.make_set_of_connected_states(state_nos, traj_processor.graph_mat)\n",
    "            connected_states_of_true_state = traj_processor.connected_states(true_state, set_of_connected_states)\n",
    "            connected_coords_of_true_state = traj_processor.states_to_coords(connected_states_of_true_state)\n",
    "            \n",
    "            true_coord = traj_processor.state_to_coord(true_state)\n",
    "            \n",
    "            mec.load(connected_coords_of_true_state, connected_states_of_true_state)\n",
    "            mec.build_distribution(epsilon)\n",
    "            \n",
    "            perturbed_coord = mec.perturb(true_coord)\n",
    "            perturbed_state = traj_processor.find_nearest_state(perturbed_coord)\n",
    "            perturbed_trajectory[i] = perturbed_state\n",
    "            \n",
    "            prior_distribution = mec.inference(pos_dist, perturbed_coord)\n",
    "            \n",
    "        reports[\"perturbed_trajectories\"].append(perturbed_trajectory)\n",
    "        \n",
    "    return reports\n",
    "\n",
    "def perturb_trajectories(trajs, traj_processor, epsilon, mec, iter_num=1, initial_constraint_domain=None):\n",
    "    reports = []\n",
    "    for traj in trajs:\n",
    "        reports.append(perturb_trajectory(traj, traj_processor, epsilon, mec, iter_num=iter_num, initial_constraint_domain_tp=initial_constraint_domain))\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_with_pg = mechanism_with_policy_graph.PlanarIsotropicMechanismWithPolicyGraph()\n",
    "lm_with_pg = mechanism_with_policy_graph.LaplaceMechanismWithPolicyGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geolife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolife_datadir = \"/data/takagi/globefish/Geolife Trajectories 1.3/Data\"\n",
    "users = os.listdir(geolife_datadir)\n",
    "\n",
    "def extract_latlon(record):\n",
    "    record = record.split(\",\")\n",
    "    return [float(record[0]), float(record[1])]\n",
    "\n",
    "trajs = []\n",
    "for user in users:\n",
    "    datadir = os.path.join(geolife_datadir, user)\n",
    "    traj_dirs = os.listdir(os.path.join(datadir, \"Trajectory\"))\n",
    "    \n",
    "    trajs_for_each_user = []\n",
    "    for traj_dir in traj_dirs:\n",
    "        traj_dir = os.path.join(datadir, \"Trajectory\", traj_dir)\n",
    "        with open(traj_dir) as f:\n",
    "            traj = [extract_latlon(record) for record in f.readlines()[6:]]\n",
    "            trajs.append(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = trajectory_processor.TrajectoryProcessor(n_x_lattice)\n",
    "tp.make_map_from_latlon(max_lat=39.988695, max_lon=116.467438, min_lat=39.831741, min_lon=116.273804)\n",
    "n_split = tp.cp_n_split(5)\n",
    "tp.make_graph_from_area(n_split=n_split, r=float(\"inf\"))\n",
    "state_trajs = tp.trajs_to_state_trajs(trajs)\n",
    "tp.make_transmat_from_state_trajs(state_trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_subgraph_x_nodes = [3, 4, 5]\n",
    "\n",
    "tps = []\n",
    "\n",
    "for n_subgraph_x_nodes in list_n_subgraph_x_nodes:\n",
    "    tp_ = trajectory_processor.TrajectoryProcessor(n_x_lattice)\n",
    "    n_split = tp_.cp_n_split(n_subgraph_x_nodes)\n",
    "    tp_.make_map_from_latlon(max_lat=39.988695, max_lon=116.467438, min_lat=39.831741, min_lon=116.273804)\n",
    "    tp_.make_graph_from_area(n_split=n_split, r=float(\"inf\"))\n",
    "    tp_.transition_mat = tp.transition_mat\n",
    "    \n",
    "    tps.append(tp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(result, win=10):\n",
    "    return [np.average(result[max(i-win*2, 0):i+win*2]) for i in range(len(result))]\n",
    "\n",
    "def distance(true_state_traj, perturbed_state_trajs, tp):\n",
    "    distances = []\n",
    "    true_coords = tp.states_to_coords(true_state_traj)\n",
    "    for perturbed_state_traj in perturbed_state_trajs:\n",
    "        perturbed_coords = tp.states_to_coords(perturbed_state_traj)[:100]\n",
    "        distances.append(np.linalg.norm(true_coords - perturbed_coords, axis=1) * tp.lattice_length)\n",
    "    return np.average(distances, axis=0)\n",
    "\n",
    "def ave_distance(reports, tp):\n",
    "    distances = []\n",
    "    for report in reports:\n",
    "        distances.append(distance(report[\"true_trajectory\"], report[\"perturbed_trajectories\"], tp))\n",
    "    return np.average(distances, axis=0) / 1000\n",
    "\n",
    "def ave_ave_distance(reports, tp):\n",
    "    distances = []\n",
    "    for report in reports:\n",
    "        distances.append(distance(report[\"true_trajectory\"], report[\"perturbed_trajectories\"], tp))\n",
    "    return np.average(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "epsilons = [0.3, 0.5, 1, 2]\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    for i, tp in enumerate(tps):\n",
    "\n",
    "        np.random.seed(0)\n",
    "        pim_reports = perturb_trajectories(state_trajs[:20], tp, epsilon, pim_with_pg, iter_num=20)\n",
    "        lm_reports = perturb_trajectories(state_trajs[:20], tp, epsilon, lm_with_pg, iter_num=20)\n",
    "\n",
    "        joblib.dump(filename=f\"epsilon_{epsilon}_{i}.jbl\", value=[pim_reports, lm_reports])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 2\n",
    "k9_pim_reports, k9_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_0.jbl\")\n",
    "k16_pim_reports, k16_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_1.jbl\")\n",
    "k25_pim_reports, k25_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_2.jbl\")\n",
    "\n",
    "k9_2_pim_distance = ave_ave_distance(k9_pim_reports, tps[0])\n",
    "k16_2_pim_distance = ave_ave_distance(k16_pim_reports, tps[1])\n",
    "k25_2_pim_distance = ave_ave_distance(k25_pim_reports, tps[2])\n",
    "\n",
    "epsilon = 0.3\n",
    "k9_pim_reports, k9_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_0.jbl\")\n",
    "k16_pim_reports, k16_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_1.jbl\")\n",
    "k25_pim_reports, k25_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_2.jbl\")\n",
    "\n",
    "k9_03_pim_distance = ave_ave_distance(k9_pim_reports, tps[0])\n",
    "k16_03_pim_distance = ave_ave_distance(k16_pim_reports, tps[1])\n",
    "k25_03_pim_distance = ave_ave_distance(k25_pim_reports, tps[2])\n",
    "\n",
    "epsilon = 0.5\n",
    "k9_pim_reports, k9_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_0.jbl\")\n",
    "k16_pim_reports, k16_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_1.jbl\")\n",
    "k25_pim_reports, k25_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_2.jbl\")\n",
    "\n",
    "k9_05_pim_distance = ave_ave_distance(k9_pim_reports, tps[0])\n",
    "k16_05_pim_distance = ave_ave_distance(k16_pim_reports, tps[1])\n",
    "k25_05_pim_distance = ave_ave_distance(k25_pim_reports, tps[2])\n",
    "\n",
    "epsilon = 1\n",
    "k9_pim_reports, k9_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_0.jbl\")\n",
    "k16_pim_reports, k16_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_1.jbl\")\n",
    "k25_pim_reports, k25_lm_reports = joblib.load(filename=f\"epsilon_{epsilon}_2.jbl\")\n",
    "\n",
    "k9_1_pim_distance = ave_ave_distance(k9_pim_reports, tps[0])\n",
    "k16_1_pim_distance = ave_ave_distance(k16_pim_reports, tps[1])\n",
    "k25_1_pim_distance = ave_ave_distance(k25_pim_reports, tps[2])\n",
    "\n",
    "k9 = [k9_03_pim_distance, k9_05_pim_distance, k9_1_pim_distance, k9_2_pim_distance]\n",
    "k16 = [k16_03_pim_distance, k16_05_pim_distance, k16_1_pim_distance, k16_2_pim_distance]\n",
    "k25 = [k25_03_pim_distance, k25_05_pim_distance, k25_1_pim_distance, k25_2_pim_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(results, y_name, filename=\"temp\"):\n",
    "    k9, k16, k25 = results\n",
    "    \n",
    "    x = np.arange(len(epsilons))\n",
    "    width = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width, np.array(k9) / 1000, width, label='K9')\n",
    "    rects2 = ax.bar(x, np.array(k16) / 1000, width, label='K16')\n",
    "    rects3 = ax.bar(x + width, np.array(k25) /1000, width, label='K25')\n",
    "    ax.set_xticks(x)\n",
    "    \n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend(loc = \"best\", fontsize=10)\n",
    "    ax.set_ylabel('average of $E_{}$'.format(\"{\" + y_name + \"}\"))\n",
    "    ax.set_xticklabels(epsilons)\n",
    "    plt.xlabel(\"$\\epsilon$\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(filename + \".eps\", bbox_inches='tight', pad_inches=0,  transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "plot_bar([k9, k16, k25], \"eu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k9_pim_distances = ave_distance(k9_pim_reports, tp)\n",
    "k16_pim_distances = ave_distance(k16_pim_reports, tp)\n",
    "k25_pim_distances = ave_distance(k25_pim_reports, tp)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.ylabel(\"$E_{eu}$\")\n",
    "plt.xlabel(\"timestamp\")\n",
    "plt.plot(smoothing(k9_pim_distances), label=\"$G_{k9}$\", linestyle=\"dotted\")\n",
    "plt.plot(smoothing(k16_pim_distances), label=\"$G_{k16}$\", linestyle=\"dashed\")\n",
    "plt.plot(smoothing(k25_pim_distances), label=\"$G_{k25}$\")\n",
    "plt.legend(fontsize=10, loc=\"upper right\", bbox_to_anchor=(1,0.9))\n",
    "plt.savefig(\"geolife.eps\", bbox_inches='tight', pad_inches=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_distances = ave_distance(k9_pim_reports, tp)\n",
    "lm_distances = ave_distance(k9_lm_reports, tp)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.ylabel(\"$E_{eu}$\")\n",
    "plt.xlabel(\"timestamp\")\n",
    "plt.plot(smoothing(pim_distances), label=\"P-PIM\")\n",
    "plt.plot(smoothing(lm_distances), label=\"P-LM\", linestyle=\"dotted\")\n",
    "plt.legend(fontsize=10)\n",
    "plt.savefig(\"9k.eps\", bbox_inches='tight', pad_inches=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_distances = ave_distance(k16_pim_reports, tp)\n",
    "lm_distances = ave_distance(k16_lm_reports, tp)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.ylabel(\"$E_{eu}$\")\n",
    "plt.xlabel(\"timestamp\")\n",
    "plt.plot(smoothing(pim_distances), label=\"P-PIM\")\n",
    "plt.plot(smoothing(lm_distances), label=\"P-LM\", linestyle=\"dotted\")\n",
    "plt.legend(fontsize=10)\n",
    "plt.savefig(\"16k.eps\", bbox_inches='tight', pad_inches=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_distances = ave_distance(k25_pim_reports, tp)\n",
    "lm_distances = ave_distance(k25_lm_reports, tp)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.ylabel(\"$E_{eu}$\")\n",
    "plt.xlabel(\"timestamp\")\n",
    "plt.plot(smoothing(pim_distances), label=\"P-PIM\")\n",
    "plt.plot(smoothing(lm_distances), label=\"P-LM\", linestyle=\"dotted\")\n",
    "plt.legend(fontsize=10)\n",
    "plt.savefig(\"25k.eps\", bbox_inches='tight', pad_inches=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gowalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_in(latlon):\n",
    "    return (min_lat <= latlon[0] <= max_lat) and (min_lon <= -latlon[1] <= max_lon)\n",
    "\n",
    "gowalla_datadir = \"/data/takagi/globefish/loc-gowalla_totalCheckins.txt\"\n",
    "n_id = 107093\n",
    "trajs = {}\n",
    "with open(gowalla_datadir) as gowalla_data:\n",
    "    pre_id = 0\n",
    "    for loc in gowalla_data:\n",
    "        splitted = loc.split(\"\\t\")\n",
    "        id = int(splitted[0])\n",
    "        if id not in trajs.keys():\n",
    "            trajs[id] = []\n",
    "        else:\n",
    "            trajs[id].append((float(splitted[2]), float(splitted[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x_lattice = 50\n",
    "min_lat = 34.02\n",
    "max_lat = 34.18\n",
    "min_lon = 118.2\n",
    "max_lon = 118.4\n",
    "            \n",
    "in_trajs = []\n",
    "for traj in trajs.values():\n",
    "    in_traj = np.array(traj)[np.where([judge_in(latlon) for latlon in traj])]\n",
    "    if not len(in_traj) <= 1:\n",
    "        in_trajs.append(np.abs(in_traj))\n",
    "        \n",
    "tp = trajectory_processor.TrajectoryProcessor(n_x_lattice)\n",
    "tp.make_map_from_latlon(max_lat=max_lat, max_lon=max_lon, min_lat=min_lat, min_lon=min_lon)\n",
    "state_trajs = tp.trajs_to_state_trajs(in_trajs)\n",
    "tp.make_transmat_from_state_trajs(state_trajs)\n",
    "\n",
    "test_trajs = [traj for traj in state_trajs if len(traj) >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perturb_trajectory(traj, traj_processor, epsilon, mec, iter_num=1):\n",
    "    reports = {\"true_trajectory\": traj[:100], \"perturbed_trajectories\": []}\n",
    "    \n",
    "    mec.policy_mat = traj_processor.graph_mat\n",
    "    \n",
    "    for f in range(iter_num):\n",
    "        \n",
    "        print(\"\\n\" + str(f))\n",
    "        \n",
    "        prior_distribution = np.zeros(len(traj_processor.transition_mat[0]))\n",
    "        prior_distribution[traj[0]] = 1\n",
    "        \n",
    "        perturbed_trajectory = np.zeros(len(traj[:100]))\n",
    "\n",
    "        for i, true_state in enumerate(traj[:100]):\n",
    "            print(i, end=\"\\r\")\n",
    "\n",
    "            pos_dist = traj_processor.compute_posterior_distribution(prior_distribution)\n",
    "            state_nos = traj_processor.compute_possible_set(pos_dist, delta=0)\n",
    "            \n",
    "            set_of_connected_states = traj_processor.make_set_of_connected_states(state_nos, traj_processor.graph_mat)\n",
    "            connected_states_of_true_state = traj_processor.connected_states(true_state, set_of_connected_states)\n",
    "            if connected_states_of_true_state == None:\n",
    "                connected_states_of_true_state = traj_processor.areas[traj_processor.state_to_area_state(true_state)]\n",
    "            connected_coords_of_true_state = traj_processor.states_to_coords(connected_states_of_true_state)\n",
    "            \n",
    "            true_coord = traj_processor.state_to_coord(true_state)\n",
    "            \n",
    "            mec.load(connected_coords_of_true_state, connected_states_of_true_state)\n",
    "            mec.build_distribution(epsilon)\n",
    "            \n",
    "            perturbed_coord = mec.perturb(true_coord)\n",
    "            perturbed_state = traj_processor.find_nearest_state(perturbed_coord)\n",
    "            perturbed_trajectory[i] = perturbed_state\n",
    "            \n",
    "            prior_distribution = mec.inference(pos_dist, perturbed_coord)\n",
    "            \n",
    "        reports[\"perturbed_trajectories\"].append(perturbed_trajectory)\n",
    "        \n",
    "    return reports\n",
    "\n",
    "def perturb_trajectories(trajs, traj_processor, epsilon, mec, iter_num=1):\n",
    "    reports = []\n",
    "    for traj in trajs:\n",
    "        reports.append(perturb_trajectory(traj, traj_processor, epsilon, mec, iter_num=iter_num))\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_subgraph_x_nodes = [3, 4, 5]\n",
    "\n",
    "tps = []\n",
    "\n",
    "for n_subgraph_x_nodes in list_n_subgraph_x_nodes:\n",
    "    tp_ = trajectory_processor.TrajectoryProcessor(n_x_lattice)\n",
    "    n_split = tp_.cp_n_split(n_subgraph_x_nodes)\n",
    "    tp_.make_map_from_latlon(max_lat=max_lat, max_lon=max_lon, min_lat=min_lat, min_lon=min_lon)\n",
    "    tp_.make_graph_from_area(n_split=n_split, r=float(\"inf\"))\n",
    "    tp_.transition_mat = tp.transition_mat\n",
    "    \n",
    "    tps.append(tp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [1]\n",
    "pim_with_pg = mechanism_with_policy_graph.PlanarIsotropicMechanismWithPolicyGraph()\n",
    "\n",
    "reports = []\n",
    "for epsilon in epsilons:\n",
    "    for i, tp in enumerate(tps):\n",
    "\n",
    "        np.random.seed(0)\n",
    "        pim_reports = perturb_trajectories(test_trajs[:20], tp, epsilon, pim_with_pg, iter_num=20)\n",
    "        reports.append(pim_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k9_pim_distances = ave_distance(reports[0], tp)\n",
    "k16_pim_distances = ave_distance(reports[1], tp)\n",
    "k25_pim_distances = ave_distance(reports[2], tp)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.ylabel(\"$E_{eu}$\")\n",
    "plt.xlabel(\"timestamp\")\n",
    "plt.plot(smoothing(k9_pim_distances), label=\"$G_{k9}$\", linestyle=\"dotted\")\n",
    "plt.plot(smoothing(k16_pim_distances), label=\"$G_{k16}$\", linestyle=\"dashed\")\n",
    "plt.plot(smoothing(k25_pim_distances), label=\"$G_{k25}$\")\n",
    "plt.legend(fontsize=10, loc=\"upper right\", bbox_to_anchor=(1,0.9))\n",
    "plt.savefig(\"gowalla.eps\", bbox_inches='tight', pad_inches=0 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
